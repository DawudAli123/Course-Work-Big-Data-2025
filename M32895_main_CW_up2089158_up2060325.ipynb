{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f311687a",
   "metadata": {},
   "source": [
    "# Main Causework UP2089158 UP2060325"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1901c81a",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee028c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar100\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6435ad3",
   "metadata": {},
   "source": [
    "## Settings & Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b16107",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # tf will show error messages only (reduce verbosity)\n",
    "sns.set_style('white')\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar100.load_data()\n",
    "print(X_train.shape, X_test.shape)\n",
    "\n",
    "n_labels = len(np.unique(y_train))\n",
    "n_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa34f173",
   "metadata": {},
   "source": [
    "## Workflow for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711fbb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "pointer = 60 # number of image in the dataset (remember, numbering starts from 0!)\n",
    "\n",
    "print(f\"array pointer = {pointer}\")\n",
    "print(f\"x_train[{pointer}] shape: {X_train[pointer].shape}\")\n",
    "print(f\"label: {y_train[pointer]}\")\n",
    "\n",
    "plt.imshow(X_train[pointer],cmap='Accent')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e69da2",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eac0e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_images(dataset, dataset_name):\n",
    "    \"\"\"\n",
    "    Checks images for:\n",
    "    * being an array\n",
    "    * shape (28x28)\n",
    "    * colour channel values\n",
    "    * NaN values\n",
    "    \"\"\"\n",
    "    invalid_count = 0  # Counter for invalid images\n",
    "    valid_count = 0     # Counter for valid images\n",
    "\n",
    "    for idx, image in enumerate(dataset):\n",
    "        # Check if the image is a NumPy array\n",
    "        if not isinstance(image, np.ndarray):\n",
    "            print(f\"{dataset_name} - Index {idx}: Not a valid image array\")\n",
    "            invalid_count += 1\n",
    "            continue\n",
    "\n",
    "        # Check shape (should be 28x28)\n",
    "        if image.shape != (28, 28):\n",
    "            print(f\"{dataset_name} - Index {idx}: Incorrect shape {image.shape}\")\n",
    "            invalid_count += 1\n",
    "            continue\n",
    "\n",
    "        # Check if values are within expected range (0-255 for grayscale images)\n",
    "        if not (image.dtype == np.uint8 and image.min() >= 0 and image.max() <= 255):\n",
    "            print(f\"{dataset_name} - Index {idx}: Invalid pixel values (Min: {image.min()}, Max: {image.max()})\")\n",
    "            invalid_count += 1\n",
    "            continue\n",
    "\n",
    "        # Check for NaN values\n",
    "        if np.isnan(image).any():\n",
    "            print(f\"{dataset_name} - Index {idx}: Contains NaN values\")\n",
    "            invalid_count += 1\n",
    "            continue\n",
    "\n",
    "        valid_count += 1\n",
    "\n",
    "    print(f\"\\n{dataset_name}: {valid_count} valid images, {invalid_count} invalid images\")\n",
    "\n",
    "    # Run checks on both datasets\n",
    "print(\"Checking Images...\\n\")\n",
    "check_images(X_train, \"Train\")\n",
    "check_images(X_test, \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c688ca0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "                                    X_train,\n",
    "                                    y_train,\n",
    "                                    test_size=0.2,\n",
    "                                    random_state=0\n",
    "                                    )\n",
    "\n",
    "print(\"* Train set:\", X_train.shape, y_train.shape)\n",
    "print(\"* Validation set:\",  X_val.shape, y_val.shape)\n",
    "print(\"* Test set:\",   X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275d2b15",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e9fa4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define class names. CIFER 100 labels\n",
    "class_names = [\n",
    "    'apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', 'bicycle', 'bottle',\n",
    "    'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel', 'can', 'castle', 'caterpillar', 'cattle',\n",
    "    'chair', 'chimpanzee', 'clock', 'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur',\n",
    "    'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', 'house', 'kangaroo', 'keyboard',\n",
    "    'lamp', 'lawn_mower', 'leopard', 'lion', 'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain',\n",
    "    'mouse', 'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear', 'pickup_truck', 'pine_tree',\n",
    "    'plain', 'plate', 'poppy', 'porcupine', 'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket',\n",
    "    'rose', 'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake', 'spider',\n",
    "    'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table', 'tank', 'telephone', 'television', 'tiger', 'tractor',\n",
    "    'train', 'trout', 'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman', 'worm'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35a27b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for label frequency distribution\n",
    "df_freq = pd.DataFrame(columns=['Set', 'Label', 'Frequency'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a41a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_labels(dataset, dataset_name):\n",
    "    \"\"\"\n",
    "    Helper function to count occurrences of each label and print them\n",
    "    \"\"\"\n",
    "    global df_freq\n",
    "    unique, counts = np.unique(dataset, return_counts=True)  # Get label frequencies\n",
    "    for label, frequency in zip(unique, counts):\n",
    "        df_freq = pd.concat([df_freq, pd.DataFrame([{'Set': dataset_name, 'Label': class_names[label], 'Frequency': frequency}])], ignore_index=True)\n",
    "        print(f\"* {dataset_name} - {class_names[label]}: {frequency} images\")  # Print formatted output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dfd6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_labels(y_train, \"Train\")\n",
    "count_labels(y_test, \"Test\")\n",
    "count_labels(y_val, \"Validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8de591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the label distribution and save image\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(20, 6))\n",
    "sns.barplot(data=df_freq, x='Set', y='Frequency', hue='Label')\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Label Frequency Distribution in Train, Validation, and Test Sets\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e8ca4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current data shape:\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdddf1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape CIFER 100 data for CNN\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_val = X_val.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "\n",
    "# Check the new shape\n",
    "print(X_train.shape)  # Expected output: (48000, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f9dd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6217f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Convert labels to categorical format**\n",
    "n_labels = 100  # CIFER 100 classes\n",
    "y_train = to_categorical(y_train, num_classes=n_labels)\n",
    "y_val = to_categorical(y_val, num_classes=n_labels)\n",
    "y_test = to_categorical(y_test, num_classes=n_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55505dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52473d7",
   "metadata": {},
   "source": [
    "## Building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48c43f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1: Baseline CNN \n",
    "def build_tf_model(input_shape, n_labels):\n",
    "  model = Sequential()\n",
    "\n",
    "  model.add(Conv2D(filters=16, kernel_size=(3,3),input_shape=input_shape, activation='relu',))\n",
    "  model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "  model.add(Conv2D(filters=16, kernel_size=(3,3), activation='relu',))\n",
    "  model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "  model.add(Flatten())\n",
    "\n",
    "  model.add(Dense(128, activation='relu'))\n",
    "  model.add(Dropout(0.25))\n",
    "\n",
    "  model.add(Dense(n_labels, activation='softmax'))\n",
    "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08be5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_tf_model(input_shape=X_train.shape[1:], n_labels=n_labels )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7969dbb",
   "metadata": {},
   "source": [
    "## Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd59ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=1)\n",
    "\n",
    "model = build_tf_model(input_shape= X_train.shape[1:], n_labels=n_labels )\n",
    "\n",
    "model.fit(x=X_train,\n",
    "          y=y_train,\n",
    "          epochs=10,\n",
    "          validation_data=(X_val, y_val),\n",
    "          verbose=1,\n",
    "          callbacks=[early_stop]\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bf8157",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5037921",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = pd.DataFrame(model.history.history)\n",
    "history.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ec7288",
   "metadata": {},
   "source": [
    "## Plot accuracy and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fa5ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "history[['loss','val_loss']].plot(style='.-')\n",
    "plt.title(\"Loss\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\")\n",
    "history[['accuracy','val_accuracy']].plot(style='.-')\n",
    "plt.title(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60f2520",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b688570a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_and_report(X,y,pipeline,label_map):\n",
    "  \"\"\"\n",
    "  Print confusion matrix and report\n",
    "  \"\"\"\n",
    "  # the prediction comes in a one hot encoded format\n",
    "  prediction = pipeline.predict(X)\n",
    "  # so we take the index from the highest probability, which is the \"winner\" or predicted class\n",
    "  prediction = np.argmax(prediction, axis=1)\n",
    "\n",
    "  # we also take the index from the highest probability from the actual values\n",
    "  y = np.argmax(y, axis=1)\n",
    "\n",
    "  print('---  Confusion Matrix  ---')\n",
    "  print(pd.DataFrame(confusion_matrix(y_true=prediction, y_pred=y),\n",
    "        columns=[ [\"Actual \" + sub for sub in label_map] ],\n",
    "        index= [ [\"Prediction \" + sub for sub in label_map ]]\n",
    "        ))\n",
    "  print(\"\\n\")\n",
    "\n",
    "  print('---  Classification Report  ---')\n",
    "  print(classification_report(y, prediction, target_names=label_map),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a6b966",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clf_performance(X_train,y_train,X_test,y_test,X_val, y_val,pipeline,label_map):\n",
    "  \"\"\"\n",
    "  Print classification performance\n",
    "  \"\"\"\n",
    "  print(\"#### Train Set #### \\n\")\n",
    "  confusion_matrix_and_report(X_train,y_train,pipeline,label_map)\n",
    "\n",
    "  print(\"#### Validation Set #### \\n\")\n",
    "  confusion_matrix_and_report(X_val,y_val,pipeline,label_map)\n",
    "\n",
    "  print(\"#### Test Set ####\\n\")\n",
    "  confusion_matrix_and_report(X_test,y_test,pipeline,label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003a9cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_performance(X_train, y_train,\n",
    "                X_test,y_test,\n",
    "                X_val, y_val,\n",
    "                model,\n",
    "                label_map= class_names\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1372cf",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92359cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 102\n",
    "my_garment = X_test[index]\n",
    "class_index = np.argmax(y_test[index])\n",
    "print(\"Image shape:\", my_garment.shape)\n",
    "print(\"One-hot label:\", y_test[index])\n",
    "print(f\"This is '{class_names[class_index]}'\")\n",
    "\n",
    "sns.set_style('white')\n",
    "plt.imshow(my_garment)  # No reshape needed; it's already (32, 32, 3)\n",
    "plt.title(f\"Class: {class_names[class_index]}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec047f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_garment.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19715d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "live_data = np.expand_dims(my_garment, axis=0)\n",
    "print(live_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8987aac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_proba = model.predict(live_data)\n",
    "prediction_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30a3bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_class = np.argmax(prediction_proba, axis=1)\n",
    "prediction_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d4c8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty dataframe, that will show the probability per class\n",
    "# we set the probabilities as the prediction_proba\n",
    "prob_per_class= pd.DataFrame(data=prediction_proba[0],\n",
    "                             columns=['Probability']\n",
    "                             )\n",
    "\n",
    "# we round the values to 3 decimal points, for better visualization\n",
    "prob_per_class = prob_per_class.round(3)\n",
    "\n",
    "# we add a column to prob_per_class that shows the meaning of each class\n",
    "# in this case, the species name that is mapped in the target_classes\n",
    "prob_per_class['Results'] = class_names\n",
    "\n",
    "prob_per_class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce12886",
   "metadata": {},
   "source": [
    "## Plot prediction probability for each garment in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc81dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(\n",
    "        prob_per_class,\n",
    "        x = 'Results',\n",
    "        y = 'Probability',\n",
    "        range_y=[0,1],\n",
    "        width=600, height=400,template='seaborn')\n",
    "fig.update_xaxes(type='category')\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
