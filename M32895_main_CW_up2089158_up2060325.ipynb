{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f311687a",
   "metadata": {},
   "source": [
    "# Main Causework UP2089158 UP2060325"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1901c81a",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee028c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar100\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6435ad3",
   "metadata": {},
   "source": [
    "## Settings & Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b16107",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # tf will show error messages only (reduce verbosity)\n",
    "sns.set_style('white')\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar100.load_data()\n",
    "print(X_train.shape, X_test.shape)\n",
    "\n",
    "n_labels = len(np.unique(y_train))\n",
    "n_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa34f173",
   "metadata": {},
   "source": [
    "## Workflow for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711fbb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "pointer = 60 # number of image in the dataset (remember, numbering starts from 0!)\n",
    "\n",
    "print(f\"array pointer = {pointer}\")\n",
    "print(f\"x_train[{pointer}] shape: {X_train[pointer].shape}\")\n",
    "print(f\"label: {y_train[pointer]}\")\n",
    "\n",
    "plt.imshow(X_train[pointer],cmap='Accent')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e69da2",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eac0e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_images(dataset, dataset_name):\n",
    "    \"\"\"\n",
    "    Checks images for:\n",
    "    * being an array\n",
    "    * shape (28x28)\n",
    "    * colour channel values\n",
    "    * NaN values\n",
    "    \"\"\"\n",
    "    invalid_count = 0  # Counter for invalid images\n",
    "    valid_count = 0     # Counter for valid images\n",
    "\n",
    "    for idx, image in enumerate(dataset):\n",
    "        # Check if the image is a NumPy array\n",
    "        if not isinstance(image, np.ndarray):\n",
    "            print(f\"{dataset_name} - Index {idx}: Not a valid image array\")\n",
    "            invalid_count += 1\n",
    "            continue\n",
    "\n",
    "        # Check shape (should be 28x28)\n",
    "        if image.shape != (28, 28):\n",
    "            print(f\"{dataset_name} - Index {idx}: Incorrect shape {image.shape}\")\n",
    "            invalid_count += 1\n",
    "            continue\n",
    "\n",
    "        # Check if values are within expected range (0-255 for grayscale images)\n",
    "        if not (image.dtype == np.uint8 and image.min() >= 0 and image.max() <= 255):\n",
    "            print(f\"{dataset_name} - Index {idx}: Invalid pixel values (Min: {image.min()}, Max: {image.max()})\")\n",
    "            invalid_count += 1\n",
    "            continue\n",
    "\n",
    "        # Check for NaN values\n",
    "        if np.isnan(image).any():\n",
    "            print(f\"{dataset_name} - Index {idx}: Contains NaN values\")\n",
    "            invalid_count += 1\n",
    "            continue\n",
    "\n",
    "        valid_count += 1\n",
    "\n",
    "    print(f\"\\n{dataset_name}: {valid_count} valid images, {invalid_count} invalid images\")\n",
    "\n",
    "    # Run checks on both datasets\n",
    "print(\"Checking Images...\\n\")\n",
    "check_images(X_train, \"Train\")\n",
    "check_images(X_test, \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c688ca0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "                                    X_train,\n",
    "                                    y_train,\n",
    "                                    test_size=0.2,\n",
    "                                    random_state=0\n",
    "                                    )\n",
    "\n",
    "print(\"* Train set:\", X_train.shape, y_train.shape)\n",
    "print(\"* Validation set:\",  X_val.shape, y_val.shape)\n",
    "print(\"* Test set:\",   X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275d2b15",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e9fa4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define class names. CIFER 100 labels\n",
    "class_names = [\n",
    "    'apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', 'bicycle', 'bottle',\n",
    "    'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel', 'can', 'castle', 'caterpillar', 'cattle',\n",
    "    'chair', 'chimpanzee', 'clock', 'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur',\n",
    "    'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', 'house', 'kangaroo', 'keyboard',\n",
    "    'lamp', 'lawn_mower', 'leopard', 'lion', 'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain',\n",
    "    'mouse', 'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear', 'pickup_truck', 'pine_tree',\n",
    "    'plain', 'plate', 'poppy', 'porcupine', 'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket',\n",
    "    'rose', 'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake', 'spider',\n",
    "    'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table', 'tank', 'telephone', 'television', 'tiger', 'tractor',\n",
    "    'train', 'trout', 'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman', 'worm'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35a27b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for label frequency distribution\n",
    "df_freq = pd.DataFrame(columns=['Set', 'Label', 'Frequency'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a41a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_labels(dataset, dataset_name):\n",
    "    \"\"\"\n",
    "    Helper function to count occurrences of each label and print them\n",
    "    \"\"\"\n",
    "    global df_freq\n",
    "    unique, counts = np.unique(dataset, return_counts=True)  # Get label frequencies\n",
    "    for label, frequency in zip(unique, counts):\n",
    "        df_freq = pd.concat([df_freq, pd.DataFrame([{'Set': dataset_name, 'Label': class_names[label], 'Frequency': frequency}])], ignore_index=True)\n",
    "        print(f\"* {dataset_name} - {class_names[label]}: {frequency} images\")  # Print formatted output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dfd6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_labels(y_train, \"Train\")\n",
    "count_labels(y_test, \"Test\")\n",
    "count_labels(y_val, \"Validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8de591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the label distribution and save image\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(20, 6))\n",
    "sns.barplot(data=df_freq, x='Set', y='Frequency', hue='Label')\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Label Frequency Distribution in Train, Validation, and Test Sets\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e8ca4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current data shape:\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdddf1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape CIFER 100 data for CNN\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_val = X_val.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "\n",
    "# Check the new shape\n",
    "print(X_train.shape)  # Expected output: (48000, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f9dd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6217f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Convert labels to categorical format**\n",
    "n_labels = 100  # CIFER 100 classes\n",
    "y_train = to_categorical(y_train, num_classes=n_labels)\n",
    "y_val = to_categorical(y_val, num_classes=n_labels)\n",
    "y_test = to_categorical(y_test, num_classes=n_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55505dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52473d7",
   "metadata": {},
   "source": [
    "## Building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48c43f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1: Baseline CNN (Improved for First-Class Standards)\n",
    "def build_tf_model(input_shape, n_labels):\n",
    "  model = Sequential()\n",
    "\n",
    "  # First Convolutional Block\n",
    "  model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
    "  model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "  # Second Convolutional Block\n",
    "  model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "  model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "  model.add(Flatten())\n",
    "\n",
    "  # Dense Layers\n",
    "  model.add(Dense(256, activation='relu'))  # Increased neurons\n",
    "  model.add(Dropout(0.4))                   # Increased dropout for regularization\n",
    "\n",
    "  # Output Layer\n",
    "  model.add(Dense(n_labels, activation='softmax'))\n",
    "\n",
    "  # Compile with lower learning rate for better convergence\n",
    "  model.compile(loss='categorical_crossentropy',\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70aa39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2: Deeper CNN with Batch Normalization\n",
    "def build_tf_model_v2(input_shape, n_labels):\n",
    "  model = Sequential()\n",
    "\n",
    "  # First Conv Block\n",
    "  model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(MaxPool2D((2, 2)))\n",
    "\n",
    "  # Second Conv Block\n",
    "  model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(MaxPool2D((2, 2)))\n",
    "\n",
    "  model.add(Flatten())\n",
    "\n",
    "  # Dense Layers\n",
    "  model.add(Dense(256, activation='relu'))\n",
    "  model.add(Dropout(0.5))\n",
    "\n",
    "  # Output Layer\n",
    "  model.add(Dense(n_labels, activation='softmax'))\n",
    "\n",
    "  model.compile(loss='categorical_crossentropy',\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
    "                metrics=['accuracy'])\n",
    "  \n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69297d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 3: Compact CNN with Larger Kernels\n",
    "def build_tf_model_v3(input_shape, n_labels):\n",
    "  model = Sequential()\n",
    "\n",
    "  # First Conv Layer with 5x5 kernel\n",
    "  model.add(Conv2D(64, (5, 5), activation='relu', padding='same', input_shape=input_shape))\n",
    "  model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "  # Second Conv Layer with 5x5 kernel\n",
    "  model.add(Conv2D(128, (5, 5), activation='relu', padding='same'))\n",
    "  model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "  model.add(Flatten())\n",
    "\n",
    "  # Dense Layers\n",
    "  model.add(Dense(128, activation='relu'))\n",
    "  model.add(Dropout(0.5))\n",
    "\n",
    "  # Output Layer\n",
    "  model.add(Dense(n_labels, activation='softmax'))\n",
    "\n",
    "  model.compile(loss='categorical_crossentropy',\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=0.0003),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fb2043",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = build_tf_model(X_train.shape[1:], n_labels)\n",
    "model2 = build_tf_model_v2(X_train.shape[1:], n_labels)\n",
    "model3 = build_tf_model_v3(X_train.shape[1:], n_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7969dbb",
   "metadata": {},
   "source": [
    "## Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd59ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping callback (shared across all models)\n",
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2, restore_best_weights=True)\n",
    "\n",
    "# === Model 1 Training ===\n",
    "model1 = build_tf_model(input_shape=X_train.shape[1:], n_labels=n_labels)\n",
    "history1 = model1.fit(x=X_train,\n",
    "                      y=y_train,\n",
    "                      epochs=4,\n",
    "                      validation_data=(X_val, y_val),\n",
    "                      verbose=1,\n",
    "                      callbacks=[early_stop])\n",
    "\n",
    "# === Model 2 Training ===\n",
    "model2 = build_tf_model_v2(input_shape=X_train.shape[1:], n_labels=n_labels)\n",
    "history2 = model2.fit(x=X_train,\n",
    "                      y=y_train,\n",
    "                      epochs=4,\n",
    "                      validation_data=(X_val, y_val),\n",
    "                      verbose=1,\n",
    "                      callbacks=[early_stop])\n",
    "\n",
    "# === Model 3 Training ===\n",
    "model3 = build_tf_model_v3(input_shape=X_train.shape[1:], n_labels=n_labels)\n",
    "history3 = model3.fit(x=X_train,\n",
    "                      y=y_train,\n",
    "                      epochs=4,\n",
    "                      validation_data=(X_val, y_val),\n",
    "                      verbose=1,\n",
    "                      callbacks=[early_stop])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bf8157",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5037921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert training histories to DataFrames\n",
    "history1_df = pd.DataFrame(history1.history)\n",
    "history2_df = pd.DataFrame(history2.history)\n",
    "history3_df = pd.DataFrame(history3.history)\n",
    "\n",
    "# Add model name column to each for easy comparison\n",
    "history1_df['model'] = 'Model 1'\n",
    "history2_df['model'] = 'Model 2'\n",
    "history3_df['model'] = 'Model 3'\n",
    "\n",
    "# Combine all histories into one DataFrame\n",
    "full_history = pd.concat([history1_df, history2_df, history3_df], ignore_index=True)\n",
    "full_history.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ec7288",
   "metadata": {},
   "source": [
    "## Plot accuracy and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fa5ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Loss for All Models\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history1_df['loss'], '.-', label='Model 1 - Train Loss')\n",
    "plt.plot(history1_df['val_loss'], '.-', label='Model 1 - Val Loss')\n",
    "plt.plot(history2_df['loss'], '.-', label='Model 2 - Train Loss')\n",
    "plt.plot(history2_df['val_loss'], '.-', label='Model 2 - Val Loss')\n",
    "plt.plot(history3_df['loss'], '.-', label='Model 3 - Train Loss')\n",
    "plt.plot(history3_df['val_loss'], '.-', label='Model 3 - Val Loss')\n",
    "plt.title(\"Loss Comparison\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# Plot Accuracy for All Models\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history1_df['accuracy'], '.-', label='Model 1 - Train Acc')\n",
    "plt.plot(history1_df['val_accuracy'], '.-', label='Model 1 - Val Acc')\n",
    "plt.plot(history2_df['accuracy'], '.-', label='Model 2 - Train Acc')\n",
    "plt.plot(history2_df['val_accuracy'], '.-', label='Model 2 - Val Acc')\n",
    "plt.plot(history3_df['accuracy'], '.-', label='Model 3 - Train Acc')\n",
    "plt.plot(history3_df['val_accuracy'], '.-', label='Model 3 - Val Acc')\n",
    "plt.title(\"Accuracy Comparison\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60f2520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate all models on the test set\n",
    "test_loss1, test_acc1 = model1.evaluate(X_test, y_test, verbose=0)\n",
    "test_loss2, test_acc2 = model2.evaluate(X_test, y_test, verbose=0)\n",
    "test_loss3, test_acc3 = model3.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "# Display results\n",
    "print(f\"Model 1 - Test Accuracy: {test_acc1:.4f}, Loss: {test_loss1:.4f}\")\n",
    "print(f\"Model 2 - Test Accuracy: {test_acc2:.4f}, Loss: {test_loss2:.4f}\")\n",
    "print(f\"Model 3 - Test Accuracy: {test_acc3:.4f}, Loss: {test_loss3:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b688570a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_and_report(X, y, pipeline, label_map):\n",
    "  \"\"\"\n",
    "  Prints the confusion matrix and classification report.\n",
    "  Assumes one-hot encoded y and a trained model (pipeline).\n",
    "  \"\"\"\n",
    "  # Make predictions (probability vectors)\n",
    "  prediction = pipeline.predict(X)\n",
    "  prediction = np.argmax(prediction, axis=1)\n",
    "  y_true = np.argmax(y, axis=1)\n",
    "\n",
    "  print('---  Confusion Matrix  ---')\n",
    "  cm = confusion_matrix(y_true=y_true, y_pred=prediction)\n",
    "  cm_df = pd.DataFrame(cm,\n",
    "                       columns=[f\"Predicted: {label}\" for label in label_map],\n",
    "                       index=[f\"Actual: {label}\" for label in label_map])\n",
    "  print(cm_df)\n",
    "  print(\"\\n\")\n",
    "\n",
    "  print('---  Classification Report  ---')\n",
    "  print(classification_report(y_true, prediction, target_names=label_map, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a6b966",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clf_performance(X_train, y_train, X_test, y_test, X_val, y_val, pipeline, label_map):\n",
    "    \"\"\"\n",
    "    Prints classification performance (confusion matrix & report)\n",
    "    for Train, Validation, and Test sets using a trained model.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*30)\n",
    "    print(\"#### Train Set ####\")\n",
    "    print(\"=\"*30 + \"\\n\")\n",
    "    confusion_matrix_and_report(X_train, y_train, pipeline, label_map)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*30)\n",
    "    print(\"#### Validation Set ####\")\n",
    "    print(\"=\"*30 + \"\\n\")\n",
    "    confusion_matrix_and_report(X_val, y_val, pipeline, label_map)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*30)\n",
    "    print(\"#### Test Set ####\")\n",
    "    print(\"=\"*30 + \"\\n\")\n",
    "    confusion_matrix_and_report(X_test, y_test, pipeline, label_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003a9cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification performance for Model 1\n",
    "clf_performance(X_train, y_train,\n",
    "                X_test, y_test,\n",
    "                X_val, y_val,\n",
    "                model1,\n",
    "                label_map=class_names)\n",
    "\n",
    "# Classification performance for Model 2\n",
    "clf_performance(X_train, y_train,\n",
    "                X_test, y_test,\n",
    "                X_val, y_val,\n",
    "                model2,\n",
    "                label_map=class_names)\n",
    "\n",
    "# Classification performance for Model 3\n",
    "clf_performance(X_train, y_train,\n",
    "                X_test, y_test,\n",
    "                X_val, y_val,\n",
    "                model3,\n",
    "                label_map=class_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1372cf",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92359cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 102\n",
    "my_garment = X_test[index]\n",
    "class_index = np.argmax(y_test[index])\n",
    "print(\"Image shape:\", my_garment.shape)\n",
    "print(\"One-hot label:\", y_test[index])\n",
    "print(f\"This is '{class_names[class_index]}'\")\n",
    "\n",
    "sns.set_style('white')\n",
    "plt.imshow(my_garment)  # No reshape needed; it's already (32, 32, 3)\n",
    "plt.title(f\"Class: {class_names[class_index]}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec047f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_garment.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19715d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "live_data = np.expand_dims(my_garment, axis=0)\n",
    "print(live_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8987aac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_proba = model.predict(live_data)\n",
    "prediction_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30a3bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_class = np.argmax(prediction_proba, axis=1)\n",
    "prediction_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d4c8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty dataframe, that will show the probability per class\n",
    "# we set the probabilities as the prediction_proba\n",
    "prob_per_class= pd.DataFrame(data=prediction_proba[0],\n",
    "                             columns=['Probability']\n",
    "                             )\n",
    "\n",
    "# we round the values to 3 decimal points, for better visualization\n",
    "prob_per_class = prob_per_class.round(3)\n",
    "\n",
    "# we add a column to prob_per_class that shows the meaning of each class\n",
    "# in this case, the species name that is mapped in the target_classes\n",
    "prob_per_class['Results'] = class_names\n",
    "\n",
    "prob_per_class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce12886",
   "metadata": {},
   "source": [
    "## Plot prediction probability for each garment in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc81dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(\n",
    "        prob_per_class,\n",
    "        x = 'Results',\n",
    "        y = 'Probability',\n",
    "        range_y=[0,1],\n",
    "        width=600, height=400,template='seaborn')\n",
    "fig.update_xaxes(type='category')\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
